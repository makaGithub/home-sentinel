# audio_detector.py
"""
–ê—É–¥–∏–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä —Å YAMNet:
- –±–µ—Ä—ë—Ç –∑–≤—É–∫ –∏–∑ —Ç–æ–≥–æ –∂–µ RTSP-–ø–æ—Ç–æ–∫–∞, —á—Ç–æ –∏ –≤–∏–¥–µ–æ (config.VIDEO_URL)
- —á–µ—Ä–µ–∑ ffmpeg –≤—ã—Ç—è–≥–∏–≤–∞–µ—Ç PCM (s16le)
- –∏—Å–ø–æ–ª—å–∑—É–µ—Ç YAMNet –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–≤—É–∫–æ–≤ (—Ä–µ—á—å, –ª–∞–π —Å–æ–±–∞–∫–∏, —Å—Ç—É–∫ –≤ –¥–≤–µ—Ä—å)
- –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö –∑–≤—É–∫–æ–≤
"""

import subprocess
import threading
import time
from collections import deque

import numpy as np

try:
    import tensorflow as tf
    import tensorflow_hub as hub
    YAMNET_AVAILABLE = True
except ImportError:
    YAMNET_AVAILABLE = False

import config
import stats
from utils import log


class AudioDetector:
    def __init__(self):
        self.proc: subprocess.Popen | None = None
        self._stop = False

        # YAMNet –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.yamnet_model = None
        self.yamnet_class_names = None
        
        if YAMNET_AVAILABLE:
            try:
                log("üéµ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YAMNet...")
                self.yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ YAMNet
                class_map_path = self.yamnet_model.class_map_path().numpy().decode('utf-8')
                class_names = {}
                with open(class_map_path, 'r') as f:
                    for line in f:
                        parts = line.strip().split(',')
                        if len(parts) >= 2:
                            class_names[int(parts[0])] = parts[1]
                self.yamnet_class_names = class_names
                log("‚úÖ YAMNet –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            except Exception as e:
                log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å YAMNet: {e}")
                log("   –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ø–æ –≥—Ä–æ–º–∫–æ—Å—Ç–∏")
                self.yamnet_model = None
        else:
            log("‚ö†Ô∏è TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ø–æ –≥—Ä–æ–º–∫–æ—Å—Ç–∏")

        # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –∞—É–¥–∏–æ (YAMNet —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –æ–∫–Ω–∞–º–∏ ~0.96 —Å–µ–∫)
        # 16kHz * 0.96 = 15360 —Å—ç–º–ø–ª–æ–≤
        self.yamnet_window_size = 15680  # YAMNet —Ç—Ä–µ–±—É–µ—Ç –∏–º–µ–Ω–Ω–æ —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        self.audio_buffer = deque(maxlen=self.yamnet_window_size * 2)  # –±—É—Ñ–µ—Ä –Ω–∞ 2 –æ–∫–Ω–∞
        
        # –ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤ YAMNet –Ω–∞ –Ω–∞—à–∏ –∑–≤—É–∫–∏
        self.sound_mapping = {
            "Speech": "speech",
            "Dog": "dog_bark",
            "Dog bark, bow-wow": "dog_bark",
            "Bark": "dog_bark",
            "Knock": "door_knock",
            "Door": "door_knock",
        }
        
        # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.confidence_threshold = 0.3

        # –ê–Ω—Ç–∏-—Å–ø–∞–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Å–æ–±—ã—Ç–∏—è–º–∏, —Å–µ–∫)
        self.min_interval_sec = 5.0
        self._last_event_ts = 0.0
        self._last_detected_sound = None

    # ----------------------------------------------------
    def _start_ffmpeg(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç ffmpeg, –∫–æ—Ç–æ—Ä—ã–π –¥–æ—Å—Ç–∞—ë—Ç –∞—É–¥–∏–æ –∏–∑ RTSP –∏ –≤—ã–¥–∞—ë—Ç —Å—ã—Ä–æ–µ PCM –≤ stdout."""
        src = str(config.VIDEO_URL)

        cmd = [
            "ffmpeg",
            "-nostdin",
            "-loglevel", "error",
            "-rtsp_transport", "tcp",
            "-i", src,
            "-vn",                      # –±–µ–∑ –≤–∏–¥–µ–æ
            "-ac", "1",                 # –º–æ–Ω–æ
            "-ar", str(config.AUDIO_SAMPLE_RATE),
            "-f", "s16le",              # —Å—ã—Ä–æ–µ PCM
            "pipe:1",
        ]

        log(f"üé§ –ó–∞–ø—É—Å–∫ ffmpeg –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–∞ –¥–ª—è {src}...")
        self.proc = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL,
            bufsize=4096,
        )

    # ----------------------------------------------------
    def _classify_with_yamnet(self, audio_data: np.ndarray) -> str | None:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∑–≤—É–∫ —Å –ø–æ–º–æ—â—å—é YAMNet."""
        if not self.yamnet_model or audio_data.size < self.yamnet_window_size:
            return None
        
        try:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [-1, 1]
            audio_float = audio_data.astype(np.float32) / 32768.0
            
            # YAMNet –æ–∂–∏–¥–∞–µ—Ç –∏–º–µ–Ω–Ω–æ 15680 —Å—ç–º–ø–ª–æ–≤
            if audio_float.size > self.yamnet_window_size:
                audio_float = audio_float[:self.yamnet_window_size]
            elif audio_float.size < self.yamnet_window_size:
                # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç
                padding = np.zeros(self.yamnet_window_size - audio_float.size, dtype=np.float32)
                audio_float = np.concatenate([audio_float, padding])
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
            scores, embeddings, spectrogram = self.yamnet_model(audio_float)
            
            # –ë–µ—Ä–µ–º —Ç–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            top_indices = np.argsort(scores.numpy())[-3:][::-1]
            
            for idx in top_indices:
                confidence = float(scores.numpy()[idx])
                if confidence < self.confidence_threshold:
                    continue
                
                class_name = self.yamnet_class_names.get(int(idx), "")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–ø–ø–∏–Ω–≥
                for yamnet_name, our_sound in self.sound_mapping.items():
                    if yamnet_name.lower() in class_name.lower():
                        if our_sound in config.SOUNDS_TO_TRACK:
                            return our_sound
            
            return None
        except Exception as e:
            log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ YAMNet: {e}")
            return None

    # ----------------------------------------------------
    def _process_chunk(self, chunk: bytes):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫—É—Å–∫–∞ PCM-–¥–∞–Ω–Ω—ã—Ö."""
        if not chunk:
            return

        # int16 ‚Üí float32
        pcm = np.frombuffer(chunk, dtype=np.int16).astype(np.float32)
        if pcm.size == 0:
            return

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä
        self.audio_buffer.extend(pcm)
        
        # –ï—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è YAMNet
        if len(self.audio_buffer) >= self.yamnet_window_size and self.yamnet_model:
            audio_array = np.array(list(self.audio_buffer)[-self.yamnet_window_size:])
            detected_sound = self._classify_with_yamnet(audio_array)
            
            if detected_sound:
                now = time.time()
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω—Ç–∏-—Å–ø–∞–º –∏ —á—Ç–æ —ç—Ç–æ –Ω–æ–≤—ã–π –∑–≤—É–∫
                if (now - self._last_event_ts) > self.min_interval_sec or \
                   self._last_detected_sound != detected_sound:
                    self._last_event_ts = now
                    self._last_detected_sound = detected_sound
                    log(f"üîä –û–±–Ω–∞—Ä—É–∂–µ–Ω –∑–≤—É–∫: {detected_sound}")
                    stats.record_sound_detected(detected_sound)
        else:
            # Fallback: –ø—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ø–æ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ (–µ—Å–ª–∏ YAMNet –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
        rms = float(np.sqrt(np.mean(pcm**2)))
            rms_threshold = 1000.0

        now = time.time()
            if rms > rms_threshold and (now - self._last_event_ts) > self.min_interval_sec:
            self._last_event_ts = now
            log(f"üîä –û–±–Ω–∞—Ä—É–∂–µ–Ω –≥—Ä–æ–º–∫–∏–π –∑–≤—É–∫ (RMS={rms:.1f})")

            # –∫–∞–∫ –∑–∞–≥–ª—É—à–∫–∞: –µ—Å–ª–∏ –≤ –∫–æ–Ω—Ñ–∏–≥–µ –µ—Å—Ç—å "speech" ‚Äî –ª–æ–≥–∏—Ä—É–µ–º –µ—ë
            if "speech" in config.SOUNDS_TO_TRACK:
                stats.record_sound_detected("speech")
                elif config.SOUNDS_TO_TRACK:
                    stats.record_sound_detected(config.SOUNDS_TO_TRACK[0])

    # ----------------------------------------------------
    def audio_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —á—Ç–µ–Ω–∏—è –∞—É–¥–∏–æ –∏–∑ ffmpeg."""
        self._start_ffmpeg()
        if not self.proc or not self.proc.stdout:
            log("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å ffmpeg –¥–ª—è –∞—É–¥–∏–æ")
            return

        chunk_size = 4096

        log("üé∂ –ê—É–¥–∏–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä –∑–∞–ø—É—â–µ–Ω, —á–∏—Ç–∞—é –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫...")
        while not self._stop:
            try:
                data = self.proc.stdout.read(chunk_size)
                if not data:
                    # –º–∞–ª–µ–Ω—å–∫–∏–π sleep, —á—Ç–æ–±—ã –Ω–µ –∫—Ä—É—Ç–∏—Ç—å –ø—É—Å—Ç–æ–π —Ü–∏–∫–ª
                    time.sleep(0.05)
                    continue
                self._process_chunk(data)
            except Exception as e:
                log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–µ: {e}")
                break

        log("üõë –ê—É–¥–∏–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    # ----------------------------------------------------
    def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∞—É–¥–∏–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ."""
        t = threading.Thread(target=self.audio_loop, daemon=True)
        t.start()
        log("üéß AudioDetector –∑–∞–ø—É—â–µ–Ω –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ")

    def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä –∏ ffmpeg."""
        self._stop = True
        try:
            if self.proc:
                self.proc.kill()
        except Exception:
            pass
