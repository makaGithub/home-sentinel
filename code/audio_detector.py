# audio_detector.py
"""
–ê—É–¥–∏–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä —Å YAMNet:
- –±–µ—Ä—ë—Ç –∑–≤—É–∫ –∏–∑ —Ç–æ–≥–æ –∂–µ RTSP-–ø–æ—Ç–æ–∫–∞, —á—Ç–æ –∏ –≤–∏–¥–µ–æ (config.VIDEO_URL)
- —á–µ—Ä–µ–∑ ffmpeg –≤—ã—Ç—è–≥–∏–≤–∞–µ—Ç PCM (s16le)
- –∏—Å–ø–æ–ª—å–∑—É–µ—Ç YAMNet –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–≤—É–∫–æ–≤ (—Ä–µ—á—å, –ª–∞–π —Å–æ–±–∞–∫–∏, —Å—Ç—É–∫ –≤ –¥–≤–µ—Ä—å)
- –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö –∑–≤—É–∫–æ–≤
"""

import subprocess
import threading
import time
import traceback
from collections import deque

import numpy as np

import config
import stats
from mqtt_client import send_sound_detected
from presence_tracker import get_tracker
from utils import log


class AudioDetector:
    def __init__(self):
        classes = ', '.join(config.YAMNET_CLASSES) if config.YAMNET_CLASSES else '–≤—Å–µ'
        log(f"üéß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∑–≤—É–∫–æ–≤ YAMNet: {classes}")
        
        self.proc: subprocess.Popen | None = None
        self._stop = False
        self._enabled = False  # –î–µ—Ç–µ–∫—Ü–∏—è –Ω–∞—á–Ω—ë—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ enable()
        self._current_frame = 0  # –ù–æ–º–µ—Ä —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞ (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∏–∑ main.py)

        # YAMNet –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.yamnet_model = None
        self.yamnet_class_names = None
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å TensorFlow –∏ YAMNet
        hub = None
        yamnet_available = False
        
        try:
            log("   –ó–∞–≥—Ä—É–∑–∫–∞ TensorFlow...")
            import tensorflow as tf
            import tensorflow_hub as hub
            yamnet_available = True
        except ImportError:
            log("‚ö†Ô∏è TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –¥–µ—Ç–µ–∫—Ü–∏—è –∑–≤—É–∫–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        except Exception as e:
            log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ TensorFlow: {e}")
    
        if yamnet_available and hub is not None:
            try:
                log("   –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YAMNet...")
                self.yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ YAMNet
                import csv
                class_map_path = self.yamnet_model.class_map_path().numpy().decode('utf-8')
                class_names = {}
                with open(class_map_path, 'r') as f:
                    reader = csv.reader(f)
                    for line_num, row in enumerate(reader):
                        if line_num == 0:
                            continue
                        if len(row) >= 3:
                            try:
                                class_names[int(row[0])] = row[2]
                            except ValueError:
                                continue
                self.yamnet_class_names = class_names
                log("‚úÖ –°–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∑–≤—É–∫–æ–≤ YAMNet –≥–æ—Ç–æ–≤–∞")
            except Exception as e:
                log(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å YAMNet: {e}")
                self.yamnet_model = None

        # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –∞—É–¥–∏–æ
        self.yamnet_window_size = 15680
        self.audio_buffer = deque(maxlen=self.yamnet_window_size * 2)
        
        # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.confidence_threshold = 0.3

        # –ê–Ω—Ç–∏-—Å–ø–∞–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        self.min_interval_sec = 5.0
        self._last_event_ts = 0.0
        self._last_detected_sound = None

    # ----------------------------------------------------
    def _start_ffmpeg(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç ffmpeg, –∫–æ—Ç–æ—Ä—ã–π –¥–æ—Å—Ç–∞—ë—Ç –∞—É–¥–∏–æ –∏–∑ RTSP –∏ –≤—ã–¥–∞—ë—Ç —Å—ã—Ä–æ–µ PCM –≤ stdout."""
        src = str(config.VIDEO_URL)

        cmd = [
            "ffmpeg",
            "-nostdin",
            "-loglevel", "error",
            "-rtsp_transport", "tcp",
            "-fflags", "nobuffer",
            "-flags", "low_delay",
            "-i", src,
            "-vn",
            "-ac", "1",
            "-ar", str(config.AUDIO_SAMPLE_RATE),
            "-f", "s16le",
            "pipe:1",
        ]

        try:
            self.proc = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                bufsize=4096,
            )
            
            time.sleep(2.0)
            if self.proc.poll() is not None:
                stderr_output = ""
                if self.proc.stderr:
                    try:
                        stderr_output = self.proc.stderr.read().decode('utf-8', errors='ignore')
                    except:
                        pass
                log(f"‚ùå ffmpeg –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –∫–æ–¥–æ–º {self.proc.returncode}")
                if stderr_output:
                    log(f"   {stderr_output[-500:]}")
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ ffmpeg: {e}")
            self.proc = None

    # ----------------------------------------------------
    def _classify_with_yamnet(self, audio_data: np.ndarray) -> str | None:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∑–≤—É–∫ —Å –ø–æ–º–æ—â—å—é YAMNet."""
        if not self.yamnet_model or audio_data.size < self.yamnet_window_size:
            return None
        
        if not self.yamnet_class_names:
            return None
        
        try:
            audio_float = audio_data.astype(np.float32) / 32768.0
            
            if audio_float.size > self.yamnet_window_size:
                audio_float = audio_float[:self.yamnet_window_size]
            elif audio_float.size < self.yamnet_window_size:
                padding = np.zeros(self.yamnet_window_size - audio_float.size, dtype=np.float32)
                audio_float = np.concatenate([audio_float, padding])
            
            scores, embeddings, spectrogram = self.yamnet_model(audio_float)
            scores_np = scores.numpy()
            
            if scores_np.ndim == 2:
                scores_mean = np.mean(scores_np, axis=0)
            else:
                scores_mean = scores_np
            
            # –ë–µ—Ä—ë–º top-10 –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –æ—Ö–≤–∞—Ç–∞
            top_indices = np.argsort(scores_mean)[-10:][::-1]
            
            for idx in top_indices:
                if idx >= len(scores_mean):
                    continue
                    
                confidence = float(scores_mean[idx])
                class_name = self.yamnet_class_names.get(int(idx), "")
                class_name_lower = class_name.lower()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ class_name –ª—é–±–æ–π –∏–∑ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö –∫–ª–∞—Å—Å–æ–≤
                for tracked in config.YAMNET_CLASSES:
                    if tracked in class_name_lower:
                        # –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –≤—Å–µ—Ö –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö –∑–≤—É–∫–æ–≤
                        if confidence >= 0.1:
                            return class_name  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
            
            return None
        except Exception as e:
            log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ YAMNet: {e}")
            return None

    # ----------------------------------------------------
    def _process_chunk(self, chunk: bytes):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫—É—Å–∫–∞ PCM-–¥–∞–Ω–Ω—ã—Ö."""
        if not chunk:
            return

        pcm = np.frombuffer(chunk, dtype=np.int16).astype(np.float32)
        if pcm.size == 0:
            return

        self.audio_buffer.extend(pcm)
        
        if len(self.audio_buffer) >= self.yamnet_window_size and self.yamnet_model:
            audio_array = np.array(list(self.audio_buffer)[-self.yamnet_window_size:])
            detected_sound = self._classify_with_yamnet(audio_array)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞
            if detected_sound and self._enabled:
                now = time.time()
                if (now - self._last_event_ts) > self.min_interval_sec or \
                   self._last_detected_sound != detected_sound:
                    self._last_event_ts = now
                    self._last_detected_sound = detected_sound
                    frame_info = f" (–∫–∞–¥—Ä {self._current_frame})" if self._current_frame > 0 else ""
                    log(f"üîä –û–±–Ω–∞—Ä—É–∂–µ–Ω –∑–≤—É–∫: {detected_sound}{frame_info}")
                    stats.record_sound_detected(detected_sound)
                    send_sound_detected(detected_sound, frame=self._current_frame)
                    
                    # –£–≤–µ–¥–æ–º–ª—è–µ–º —Ç—Ä–µ–∫–µ—Ä –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è (–¥–ª—è –∑–≤—É–∫–æ–≤ –¥–≤–µ—Ä–∏)
                    tracker = get_tracker()
                    if tracker:
                        tracker.on_door_sound(detected_sound)

    # ----------------------------------------------------
    def audio_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —á—Ç–µ–Ω–∏—è –∞—É–¥–∏–æ –∏–∑ ffmpeg."""
        self._start_ffmpeg()
        if not self.proc or not self.proc.stdout:
            log("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å ffmpeg –¥–ª—è –∞—É–¥–∏–æ")
            return

        chunk_size = 4096
        
        while not self._stop:
            try:
                if self.proc.poll() is not None:
                    log(f"‚ùå ffmpeg –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –∫–æ–¥–æ–º {self.proc.returncode}")
                    break
                
                data = self.proc.stdout.read(chunk_size)
                if not data:
                    time.sleep(0.05)
                    continue
                
                self._process_chunk(data)
            except Exception as e:
                log(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–µ: {e}")
                break

    # ----------------------------------------------------
    def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∞—É–¥–∏–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ."""
        t = threading.Thread(target=self.audio_loop, daemon=True, name="AudioDetector")
        t.start()

    def enable(self):
        """–í–∫–ª—é—á–∞–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏—é –∑–≤—É–∫–æ–≤ (–≤—ã–∑—ã–≤–∞—Ç—å –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏)."""
        self._enabled = True

    def set_frame(self, frame_num: int):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –Ω–æ–º–µ—Ä —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞ (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)."""
        self._current_frame = frame_num

    def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä –∏ ffmpeg."""
        self._stop = True
        try:
            if self.proc:
                self.proc.kill()
        except Exception:
            pass
