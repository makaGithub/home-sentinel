# embeddings.py
"""
–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –ª–∏—Ü –∏–∑ Immich.
"""

import json
import os

import numpy as np

import config
from utils import ensure_dirs, _l2_normalize, log
from database import fetch_embeddings_from_db


def load_or_refresh_cache(force_refresh: bool = False):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞, –ª–∏–±–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ ‚Äî –∏–∑ –±–∞–∑—ã Immich.
    –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç:
        - embeddings_list.json: —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ –≤–µ–∫—Ç–æ—Ä–æ–≤
        - confidences_list.json: —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ confidence
    –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç (embeddings.npy + names/ids.json).
    """
    ensure_dirs()

    embeddings_list_path = os.path.join(config.CACHE_DIR, "embeddings_list.json")
    confidences_list_path = os.path.join(config.CACHE_DIR, "confidences_list.json")

    cache_exists = (
        os.path.exists(embeddings_list_path)
        and os.path.exists(config.NAMES_PATH)
        and os.path.exists(config.IDS_PATH)
    )

    if cache_exists and not force_refresh:
        log("üì¶ –ó–∞–≥—Ä—É–∂–∞—é –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞...")
        with open(embeddings_list_path, "r", encoding="utf-8") as f:
            embeddings_data = json.load(f)

        all_embs_list = []
        for person_embs in embeddings_data:
            normalized = [
                _l2_normalize(np.array(emb, dtype=np.float32)) for emb in person_embs
            ]
            all_embs_list.append(normalized)

        # Confidences
        if os.path.exists(confidences_list_path):
            with open(confidences_list_path, "r", encoding="utf-8") as f:
                all_confidences_list = json.load(f)
        else:
            all_confidences_list = [
                [1.0] * len(person_embs) for person_embs in all_embs_list
            ]

        with open(config.NAMES_PATH, "r", encoding="utf-8") as f:
            names = json.load(f)
        with open(config.IDS_PATH, "r", encoding="utf-8") as f:
            ids = json.load(f)

        log(f"‚úÖ –ö—ç—à –∑–∞–≥—Ä—É–∂–µ–Ω ({len(all_embs_list)} –ª–∏—Ü).")
        if ids:
            log("üë• –õ–∏—Ü–∞ –∏–∑ –∫—ç—à–∞:")
            for pid, name, embs_list, confs_list in zip(
                ids, names, all_embs_list, all_confidences_list
            ):
                avg_conf = sum(confs_list) / len(confs_list) if confs_list else 0.0
                log(
                    f"   - {pid:<4} | {name} "
                    f"({len(embs_list)} –≤–µ–∫—Ç–æ—Ä–æ–≤, avg confidence={avg_conf:.2f})"
                )

        return all_embs_list, names, ids, all_confidences_list

    # –ï—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç –∏–ª–∏ –Ω—É–∂–µ–Ω refresh ‚Üí –≥—Ä—É–∑–∏–º –∏–∑ –ë–î
    all_embs_list, names, ids, all_confidences_list = fetch_embeddings_from_db()

    embeddings_data = [[emb.tolist() for emb in person_embs] for person_embs in all_embs_list]
    with open(embeddings_list_path, "w", encoding="utf-8") as f:
        json.dump(embeddings_data, f, indent=2)

    with open(confidences_list_path, "w", encoding="utf-8") as f:
        json.dump(all_confidences_list, f, indent=2)

    # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç ‚Äî —Å—Ä–µ–¥–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ —á–µ–ª–æ–≤–µ–∫—É
    if all_embs_list:
        mean_embs = np.array(
            [np.vstack(person_embs).mean(axis=0) for person_embs in all_embs_list]
        )
        if mean_embs.size > 0:
            mean_embs = _l2_normalize(mean_embs)
            np.save(config.EMBEDDINGS_PATH, mean_embs)

    with open(config.NAMES_PATH, "w", encoding="utf-8") as f:
        json.dump(names, f, ensure_ascii=False, indent=2)
    with open(config.IDS_PATH, "w", encoding="utf-8") as f:
        json.dump(ids, f, indent=2)

    log("üíæ –ö—ç—à –æ–±–Ω–æ–≤–ª—ë–Ω.")
    return all_embs_list, names, ids, all_confidences_list
