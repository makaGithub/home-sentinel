# embeddings.py
"""
–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –ª–∏—Ü –∏–∑ Immich.
–•—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Ñ–∞–π–ª–∞–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞.
"""

import json
import os
import pickle

import numpy as np

import config
from utils import ensure_dirs, _l2_normalize, log
from database import fetch_embeddings_from_db


# –ü–∞–ø–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –ª—é–¥—è–º
FACES_CACHE_DIR = os.path.join(config.CACHE_DIR, "faces")


def load_or_refresh_cache(force_refresh: bool = False):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞, –ª–∏–±–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ ‚Äî –∏–∑ –±–∞–∑—ã Immich.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞.
    """
    ensure_dirs()
    os.makedirs(FACES_CACHE_DIR, exist_ok=True)

    index_path = os.path.join(FACES_CACHE_DIR, "index.json")
    cache_exists = os.path.exists(index_path)

    if cache_exists and not force_refresh:
        return _load_from_files()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –ë–î
    log("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –ª–∏—Ü –∏–∑ Immich (–∏–∑ –ë–î)...")
    all_embs_list, names, ids, all_confidences_list = fetch_embeddings_from_db()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
    _save_to_files(all_embs_list, names, ids, all_confidences_list)

    log(f"‚úÖ –ë–∞–∑–∞ –ª–∏—Ü –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({len(all_embs_list)} —á–µ–ª–æ–≤–µ–∫)")
    return all_embs_list, names, ids, all_confidences_list


def _load_from_files():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞."""
    log("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –ª–∏—Ü –∏–∑ Immich...")
    
    index_path = os.path.join(FACES_CACHE_DIR, "index.json")
    with open(index_path, "r", encoding="utf-8") as f:
        index = json.load(f)
    
    all_embs_list = []
    names = []
    ids = []
    all_confidences_list = []
    loaded_names = []  # –î–ª—è –≤—ã–≤–æ–¥–∞ –≤ –ª–æ–≥
    
    for entry in index:
        person_id = entry["id"]
        name = entry["name"]
        
        person_file = os.path.join(FACES_CACHE_DIR, f"{person_id}.pkl")
        
        with open(person_file, "rb") as f:
            person_data = pickle.load(f)
        
        all_embs_list.append(person_data["embeddings"])
        names.append(name)
        ids.append(person_id)
        all_confidences_list.append(person_data["confidences"])
        loaded_names.append(f"{name}({len(person_data['embeddings'])})")
    
    log(f"‚úÖ –ë–∞–∑–∞ –ª–∏—Ü –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({len(all_embs_list)} —á–µ–ª–æ–≤–µ–∫)")
    
    # –í—ã–≤–æ–¥–∏–º –∏–º–µ–Ω–∞ –ø–æ 5 –Ω–∞ —Å—Ç—Ä–æ–∫—É
    names_per_line = 5
    for i in range(0, len(loaded_names), names_per_line):
        chunk = loaded_names[i:i + names_per_line]
        log(f"   üë• {', '.join(chunk)}")
    
    return all_embs_list, names, ids, all_confidences_list


def _save_to_files(all_embs_list: list, names: list, ids: list, all_confidences_list: list):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞."""
    os.makedirs(FACES_CACHE_DIR, exist_ok=True)
    
    # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å
    index = []
    for person_id, name in zip(ids, names):
        index.append({"id": person_id, "name": name})
    
    index_path = os.path.join(FACES_CACHE_DIR, "index.json")
    with open(index_path, "w", encoding="utf-8") as f:
        json.dump(index, f, ensure_ascii=False, indent=2)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∂–¥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞
    for person_id, embs, confs in zip(ids, all_embs_list, all_confidences_list):
        person_data = {
            "embeddings": embs,
            "confidences": confs,
        }
        person_file = os.path.join(FACES_CACHE_DIR, f"{person_id}.pkl")
        with open(person_file, "wb") as f:
            pickle.dump(person_data, f, protocol=pickle.HIGHEST_PROTOCOL)


